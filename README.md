# flash-attention pre-build wheels

This repository provides wheels for the pre-built [flash-attention](https://github.com/Dao-AILab/flash-attention).

Since building flash-attention takes a **very long time** and is resource-intensive,
I also build and provide combinations of CUDA and PyTorch that are not officially distributed.

The building Github Actions Workflow can be found [here](./.github/workflows/build.yml).  
The built packages are available on the [release page](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases).

**This repository uses a self-hosted runner and AWS CodeBuild for building the wheels. If you find this project helpful, please consider sponsoring to help maintain the infrastructure!**

[![fund](https://img.shields.io/static/v1?label=Sponsor&message=%E2%9D%A4&logo=GitHub&color=%23fe8e86)](https://github.com/sponsors/mjun0812)

## Table of Contents

- [Install](#install)
- [Packages](#packages)
  - [Linux x86_64](#linux-x86_64)
  - [Windows x86_64](#windows-x86_64)
- [Self-build runner](#self-build)
- [History](#history)
- [Original Repository](#original-repository)

## Install

1. Select the versions for Python, CUDA, PyTorch, and flash_attn.

```bash
flash_attn-[flash_attn Version]+cu[CUDA Version]torch[PyTorch Version]-cp[Python Version]-cp[Python Version]-linux_x86_64.whl

# Example: Python 3.11, CUDA 12.4, PyTorch 2.5, and flash_attn 2.6.3
flash_attn-2.6.3+cu124torch2.5-cp312-cp312-linux_x86_64.whl
```

2. Find the corresponding version of a wheel from the below [Package section](#packages) and [releases](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases)

3. Direct Install or Download and Local Install

```bash
# Direct Install
pip install https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3+cu124torch2.5-cp312-cp312-linux_x86_64.whl

# Download and Local Install
wget https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3+cu124torch2.5-cp312-cp312-linux_x86_64.whl
pip install ./flash_attn-2.6.3+cu124torch2.5-cp312-cp312-linux_x86_64.whl
```

## Packages

### Linux x86_64

#### Flash-Attention 2.8.3

<details>
<summary>Packages for Flash-Attention 2.8.3</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.9 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.8.3%2Bcu124torch2.5-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.8.3%2Bcu126torch2.5-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.8.3%2Bcu124torch2.6-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.8.3%2Bcu126torch2.6-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.8.3%2Bcu124torch2.7-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.8.3%2Bcu126torch2.7-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.8.3%2Bcu124torch2.8-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.8 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.8.3%2Bcu126torch2.8-cp39-cp39-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu128torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu128torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu129torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu124torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu126torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu124torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu126torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu128torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu129torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.8.3%2Bcu126torch2.9-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.9 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.8.3%2Bcu128torch2.9-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.9 | 13.0 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.18/flash_attn-2.8.3%2Bcu130torch2.9-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu128torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu128torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu129torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu124torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu126torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu124torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu126torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu128torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu129torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.8.3%2Bcu126torch2.9-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.15/flash_attn-2.8.3%2Bcu126torch2.9-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.9 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.8.3%2Bcu128torch2.9-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.15/flash_attn-2.8.3%2Bcu128torch2.9-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.9 | 13.0 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.18/flash_attn-2.8.3%2Bcu130torch2.9-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu128torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu128torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu129torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu124torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu126torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu124torch2.8-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu126torch2.8-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu128torch2.8-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.11/flash_attn-2.8.3%2Bcu129torch2.8-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.8.3%2Bcu126torch2.9-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.15/flash_attn-2.8.3%2Bcu126torch2.9-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.9 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.8.3%2Bcu128torch2.9-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.15/flash_attn-2.8.3%2Bcu128torch2.9-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.9 | 13.0 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.18/flash_attn-2.8.3%2Bcu130torch2.9-cp312-cp312-linux_x86_64.whl) |
| 3.13 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.3%2Bcu124torch2.6-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.3%2Bcu126torch2.6-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.3%2Bcu128torch2.6-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.3%2Bcu129torch2.6-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.3%2Bcu124torch2.7-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.3%2Bcu126torch2.7-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.3%2Bcu128torch2.7-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.3%2Bcu124torch2.8-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.8 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.3%2Bcu126torch2.8-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.3%2Bcu128torch2.8-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.3%2Bcu129torch2.8-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.8.3%2Bcu126torch2.9-cp313-cp313-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.15/flash_attn-2.8.3%2Bcu126torch2.9-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.9 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.8.3%2Bcu128torch2.9-cp313-cp313-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.15/flash_attn-2.8.3%2Bcu128torch2.9-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.9 | 13.0 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.18/flash_attn-2.8.3%2Bcu130torch2.9-cp313-cp313-linux_x86_64.whl) |

</details>

#### Flash-Attention 2.8.2

<details>
<summary>Packages for Flash-Attention 2.8.2</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu128torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu128torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu129torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu124torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu124torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu128torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu129torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu128torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu128torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu129torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu124torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu124torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu128torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu129torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu128torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu128torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu129torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu124torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu124torch2.8-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu128torch2.8-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.8.2%2Bcu129torch2.8-cp312-cp312-linux_x86_64.whl) |

</details>

#### Flash-Attention 2.8.1

<details>
<summary>Packages for Flash-Attention 2.8.1</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.13/flash_attn-2.8.1%2Bcu128torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.13/flash_attn-2.8.1%2Bcu128torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.13/flash_attn-2.8.1%2Bcu128torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.13/flash_attn-2.8.1%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.13/flash_attn-2.8.1%2Bcu128torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.13/flash_attn-2.8.1%2Bcu128torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.13/flash_attn-2.8.1%2Bcu128torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.13/flash_attn-2.8.1%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.13/flash_attn-2.8.1%2Bcu128torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.13/flash_attn-2.8.1%2Bcu128torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.13/flash_attn-2.8.1%2Bcu128torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.13/flash_attn-2.8.1%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl) |

</details>

#### Flash-Attention 2.8.0

<details>
<summary>Packages for Flash-Attention 2.8.0</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu128torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu128torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu121torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu128torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu128torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu128torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu124torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu128torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu128torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu128torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu128torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu124torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu128torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu128torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu128torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.11/flash_attn-2.8.0%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu128torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu124torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.12/flash_attn-2.8.0%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl) |

</details>

#### Flash-Attention 2.7.4.post1

<details>
<summary>Packages for Flash-Attention 2.7.4.post1</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.9 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.7.4.post1%2Bcu124torch2.7-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.7.4.post1%2Bcu126torch2.7-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.7.4.post1%2Bcu124torch2.8-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.8 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.7.4.post1%2Bcu126torch2.8-cp39-cp39-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu118torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu118torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu118torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu118torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu126torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu126torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.7.4.post1%2Bcu126torch2.9-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.9 | 13.0 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.18/flash_attn-2.7.4.post1%2Bcu130torch2.9-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu118torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu118torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu118torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu118torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu126torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu126torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.7.4.post1%2Bcu126torch2.9-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu118torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu118torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.7.4.post1%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu118torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu118torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.7.4.post1%2Bcu126torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.7.4.post1%2Bcu126torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.7.4.post1%2Bcu126torch2.9-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.9 | 13.0 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.18/flash_attn-2.7.4.post1%2Bcu130torch2.9-cp312-cp312-linux_x86_64.whl) |
| 3.13 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.7.4.post1%2Bcu126torch2.9-cp313-cp313-linux_x86_64.whl) |

</details>

#### Flash-Attention 2.7.4

<details>
<summary>Packages for Flash-Attention 2.7.4</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.7.4%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu128torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.7.4%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu128torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu129torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu124torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.7.4%2Bcu124torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.10/flash_attn-2.7.4%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.1.0/flash_attn-2.7.4%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu124torch2.8-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.7.4%2Bcu124torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu128torch2.8-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.1/flash_attn-2.7.4%2Bcu128torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu129torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.7.4%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu128torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.7.4%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu128torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu129torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu124torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.7.4%2Bcu124torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.10/flash_attn-2.7.4%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.1.0/flash_attn-2.7.4%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu124torch2.8-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.7.4%2Bcu124torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu128torch2.8-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.1/flash_attn-2.7.4%2Bcu128torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu129torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.7.4%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu128torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.7.4%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu128torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu129torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu124torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.7.4%2Bcu124torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.10/flash_attn-2.7.4%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.1.0/flash_attn-2.7.4%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu124torch2.8-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.7.4%2Bcu124torch2.8-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu128torch2.8-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.1/flash_attn-2.7.4%2Bcu128torch2.8-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.18/flash_attn-2.7.4%2Bcu129torch2.8-cp312-cp312-linux_x86_64.whl) |

</details>

#### Flash-Attention 2.7.3

<details>
<summary>Packages for Flash-Attention 2.7.3</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.0-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.4/flash_attn-2.7.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |

</details>

#### Flash-Attention 2.7.2.post1

<details>
<summary>Packages for Flash-Attention 2.7.2.post1</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.0-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.3/flash_attn-2.7.2.post1%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |

</details>

#### Flash-Attention 2.7.0.post2

<details>
<summary>Packages for Flash-Attention 2.7.0.post2</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.0-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.7.0.post2%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |

</details>

#### Flash-Attention 2.6.3

<details>
<summary>Packages for Flash-Attention 2.6.3</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.9 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.6.3%2Bcu124torch2.5-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.6.3%2Bcu126torch2.5-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.6.3%2Bcu124torch2.6-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.6.3%2Bcu126torch2.6-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.6.3%2Bcu124torch2.7-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.6.3%2Bcu126torch2.7-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.6.3%2Bcu124torch2.8-cp39-cp39-linux_x86_64.whl) |
| 3.9 | 2.8 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.16/flash_attn-2.6.3%2Bcu126torch2.8-cp39-cp39-linux_x86_64.whl) |
| 3.10 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.0-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.0-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.1-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.1-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.1-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.1-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download6](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu128torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download6](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download7](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu128torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu128torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu118torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu118torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu128torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu128torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu129torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu118torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu118torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu124torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu126torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu126torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.1.0/flash_attn-2.6.3%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.9/flash_attn-2.6.3%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu124torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu128torch2.8-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.1/flash_attn-2.6.3%2Bcu128torch2.8-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.0/flash_attn-2.6.3%2Bcu128torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu129torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.6.3%2Bcu126torch2.9-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.9 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.6.3%2Bcu128torch2.9-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.9 | 13.0 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.18/flash_attn-2.6.3%2Bcu130torch2.9-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download6](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download7](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu128torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download6](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download7](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download8](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu128torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu128torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu118torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu118torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu128torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu128torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu129torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu118torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu118torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu124torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu126torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu126torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.1.0/flash_attn-2.6.3%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.9/flash_attn-2.6.3%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu124torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu128torch2.8-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.1/flash_attn-2.6.3%2Bcu128torch2.8-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.0/flash_attn-2.6.3%2Bcu128torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu129torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.6.3%2Bcu126torch2.9-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.9 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.6.3%2Bcu128torch2.9-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.9 | 13.0 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.18/flash_attn-2.6.3%2Bcu130torch2.9-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download6](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download7](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu128torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download6](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.6.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download7](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.6.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download8](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.6.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu128torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu128torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu118torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu118torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.6.3%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.5/flash_attn-2.6.3%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu128torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu128torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu129torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu118torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu118torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu124torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.6.3%2Bcu126torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu126torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.1.0/flash_attn-2.6.3%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.9/flash_attn-2.6.3%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.6.3%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu124torch2.8-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu128torch2.8-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.1/flash_attn-2.6.3%2Bcu128torch2.8-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.0/flash_attn-2.6.3%2Bcu128torch2.8-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.9 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.14/flash_attn-2.6.3%2Bcu129torch2.8-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.6.3%2Bcu126torch2.9-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.9 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.6.3%2Bcu128torch2.9-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.9 | 13.0 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.18/flash_attn-2.6.3%2Bcu130torch2.9-cp312-cp312-linux_x86_64.whl) |
| 3.13 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.6.3%2Bcu126torch2.9-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.9 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.17/flash_attn-2.6.3%2Bcu128torch2.9-cp313-cp313-linux_x86_64.whl) |
| 3.13 | 2.9 | 13.0 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.18/flash_attn-2.6.3%2Bcu130torch2.9-cp313-cp313-linux_x86_64.whl) |

</details>

#### Flash-Attention 2.5.9

<details>
<summary>Packages for Flash-Attention 2.5.9</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.0-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu128torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu128torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu118torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu118torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu128torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu118torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu118torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu126torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu126torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.1.0/flash_attn-2.5.9%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.9/flash_attn-2.5.9%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.1/flash_attn-2.5.9%2Bcu128torch2.8-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.0/flash_attn-2.5.9%2Bcu128torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu128torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu128torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu118torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu118torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu128torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu118torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu118torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu126torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu126torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.1.0/flash_attn-2.5.9%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.9/flash_attn-2.5.9%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.1/flash_attn-2.5.9%2Bcu128torch2.8-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.0/flash_attn-2.5.9%2Bcu128torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu128torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.9%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.9%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu128torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu118torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu118torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.5.9%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu128torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu118torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu118torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.5.9%2Bcu126torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu126torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.1.0/flash_attn-2.5.9%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.9/flash_attn-2.5.9%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.5.9%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.1/flash_attn-2.5.9%2Bcu128torch2.8-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.0/flash_attn-2.5.9%2Bcu128torch2.8-cp312-cp312-linux_x86_64.whl) |

</details>

#### Flash-Attention 2.5.6

<details>
<summary>Packages for Flash-Attention 2.5.6</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.0-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.0-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.1-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.1-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.1-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.5.6%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.5.6%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.5.6%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |

</details>

#### Flash-Attention 2.4.3

<details>
<summary>Packages for Flash-Attention 2.4.3</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.0-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.0-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.1-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.1-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.1-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu128torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu128torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu118torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu118torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu128torch2.6-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu118torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu118torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu126torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu126torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.4.3%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.1.0/flash_attn-2.4.3%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.9/flash_attn-2.4.3%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu128torch2.7-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.1/flash_attn-2.4.3%2Bcu128torch2.8-cp310-cp310-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.0/flash_attn-2.4.3%2Bcu128torch2.8-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl), [Download6](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu128torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl), [Download6](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu128torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu118torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu118torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu128torch2.6-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu118torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu118torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu126torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu126torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.4.3%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.1.0/flash_attn-2.4.3%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.9/flash_attn-2.4.3%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu128torch2.7-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.1/flash_attn-2.4.3%2Bcu128torch2.8-cp311-cp311-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.0/flash_attn-2.4.3%2Bcu128torch2.8-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl), [Download6](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu128torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.2/flash_attn-2.4.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download5](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-2.4.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl), [Download6](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.4.3%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu128torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu118torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu118torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu124torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.6/flash_attn-2.4.3%2Bcu126torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu128torch2.6-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu118torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu118torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.8/flash_attn-2.4.3%2Bcu126torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu126torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.4.3%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.1.0/flash_attn-2.4.3%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl), [Download3](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.9/flash_attn-2.4.3%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl), [Download4](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.7/flash_attn-2.4.3%2Bcu128torch2.7-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.1/flash_attn-2.4.3%2Bcu128torch2.8-cp312-cp312-linux_x86_64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.2.0/flash_attn-2.4.3%2Bcu128torch2.8-cp312-cp312-linux_x86_64.whl) |

</details>

#### Flash-Attention 1.0.9

<details>
<summary>Packages for Flash-Attention 1.0.9</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.0-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.1-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.2-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.3-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.4-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.5-cp310-cp310-linux_x86_64.whl) |
| 3.11 | 2.0 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.0-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.1 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.1-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.2-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.3-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.4-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.5-cp311-cp311-linux_x86_64.whl) |
| 3.12 | 2.2 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.2 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.2-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.3 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.3-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.4-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 11.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu118torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.1 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu121torch2.5-cp312-cp312-linux_x86_64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.1/flash_attn-1.0.9%2Bcu124torch2.5-cp312-cp312-linux_x86_64.whl) |

</details>

### Windows x86_64

#### Flash-Attention 2.8.3

<details>
<summary>Packages for Flash-Attention 2.8.3</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.11 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.15/flash_attn-2.8.3%2Bcu126torch2.9-cp311-cp311-win_amd64.whl) |
| 3.12 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.15/flash_attn-2.8.3%2Bcu126torch2.9-cp312-cp312-win_amd64.whl) |
| 3.13 | 2.9 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.15/flash_attn-2.8.3%2Bcu126torch2.9-cp313-cp313-win_amd64.whl) |

</details>

#### Flash-Attention 2.8.2

<details>
<summary>Packages for Flash-Attention 2.8.2</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.10/flash_attn-2.8.2%2Bcu128torch2.7-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.10/flash_attn-2.8.2%2Bcu128torch2.8-cp310-cp310-win_amd64.whl) |
| 3.11 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.10/flash_attn-2.8.2%2Bcu128torch2.7-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.10/flash_attn-2.8.2%2Bcu128torch2.8-cp311-cp311-win_amd64.whl) |
| 3.12 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.10/flash_attn-2.8.2%2Bcu128torch2.7-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.10/flash_attn-2.8.2%2Bcu128torch2.8-cp312-cp312-win_amd64.whl) |
| 3.13 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.2%2Bcu124torch2.6-cp313-cp313-win_amd64.whl) |
| 3.13 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.2%2Bcu124torch2.7-cp313-cp313-win_amd64.whl) |
| 3.13 | 2.7 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.2%2Bcu126torch2.7-cp313-cp313-win_amd64.whl) |
| 3.13 | 2.8 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.2%2Bcu124torch2.8-cp313-cp313-win_amd64.whl) |
| 3.13 | 2.8 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.12/flash_attn-2.8.2%2Bcu126torch2.8-cp313-cp313-win_amd64.whl) |

</details>

#### Flash-Attention 2.7.4

<details>
<summary>Packages for Flash-Attention 2.7.4</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.7.4%2Bcu124torch2.4-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.7.4%2Bcu124torch2.5-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.7.4%2Bcu124torch2.6-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.7.4%2Bcu124torch2.7-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.10/flash_attn-2.7.4%2Bcu128torch2.7-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.10/flash_attn-2.7.4%2Bcu128torch2.8-cp310-cp310-win_amd64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.7.4%2Bcu124torch2.5-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.7.4%2Bcu124torch2.7-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.10/flash_attn-2.7.4%2Bcu128torch2.7-cp311-cp311-win_amd64.whl), [Download2](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.9/flash_attn-2.7.4%2Bcu128torch2.7-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.10/flash_attn-2.7.4%2Bcu128torch2.8-cp311-cp311-win_amd64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.7.4%2Bcu124torch2.4-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.7.4%2Bcu124torch2.5-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.7.4%2Bcu124torch2.6-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.7.4%2Bcu124torch2.7-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.10/flash_attn-2.7.4%2Bcu128torch2.7-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.8 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.4.10/flash_attn-2.7.4%2Bcu128torch2.8-cp312-cp312-win_amd64.whl) |

</details>

#### Flash-Attention 2.6.3

<details>
<summary>Packages for Flash-Attention 2.6.3</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu124torch2.4-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.4-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu124torch2.5-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.5-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu124torch2.6-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.6-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu124torch2.7-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.7-cp310-cp310-win_amd64.whl) |
| 3.11 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu124torch2.4-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.4-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu124torch2.5-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.5-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu124torch2.6-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.6 | 12.6 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.1/flash_attn-2.6.3%2Bcu126torch2.6-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.6-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu124torch2.7-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.7-cp311-cp311-win_amd64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu124torch2.4-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.4-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu124torch2.5-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.5-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu124torch2.6-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.6-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu124torch2.7-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.6.3%2Bcu128torch2.7-cp312-cp312-win_amd64.whl) |

</details>

#### Flash-Attention 2.5.9

<details>
<summary>Packages for Flash-Attention 2.5.9</summary>

| Python | PyTorch | CUDA | package |
| ------ | ------- | ---- | ------- |
| 3.10 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu124torch2.4-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.4-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu124torch2.5-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.5-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu124torch2.6-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.6-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu124torch2.7-cp310-cp310-win_amd64.whl) |
| 3.10 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.7-cp310-cp310-win_amd64.whl) |
| 3.11 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu124torch2.4-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.4-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu124torch2.5-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.5-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu124torch2.6-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.6-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu124torch2.7-cp311-cp311-win_amd64.whl) |
| 3.11 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.7-cp311-cp311-win_amd64.whl) |
| 3.12 | 2.4 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu124torch2.4-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.4 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.4-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.5 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu124torch2.5-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.5 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.5-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.6 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu124torch2.6-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.6 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.6-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.7 | 12.4 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu124torch2.7-cp312-cp312-win_amd64.whl) |
| 3.12 | 2.7 | 12.8 | [Download1](https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.3.9/flash_attn-2.5.9%2Bcu128torch2.7-cp312-cp312-win_amd64.whl) |

</details>


## History

History of this repository is available [here](./docs/release_history.md).

## Self build

If you cannot find the version you are looking for, you can fork this repository and create a wheel on GitHub Actions.

1. Fork this repository
2. Edit workflow file [`.github/workflows/build.yml`](https://github.com/mjun0812/flash-attention-prebuild-wheels/blob/main/.github/workflows/build.yml) to set the version you want to build.
3. Add tag `v*.*.*` to trigger the build workflow.

Please note that depending on the combination of versions, it may not be possible to build.

### Self-Hosted Runner Build

In some version combinations, you cannot build wheels on GitHub-hosted runners due to job time limitations.
To build the wheels for these versions, you can use self-hosted runners.

```bash
git clone https://github.com/mjun0812/flash-attention-prebuild-wheels.git
cd self-hosted-runner
cp env.template env
```

Edit `env` file to set the environment variables.

```bash
# Edit env
PERSONAL_ACCESS_TOKEN=[Github Personal Access Token]
```

Edit compose.yml file if you use repository folked from this repository.

```yaml
services:
  runner:
    privileged: true
    build:
      context: .
      dockerfile: Dockerfile
      args:
        REPOSITORY_URL: [Target Repository URL]
        PERSONAL_ACCESS_TOKEN: $PERSONAL_ACCESS_TOKEN
        GH_RUNNER_VERSION: 2.324.0
        RUNNER_NAME: self-hosted-runner
        RUNNER_GROUP: default
        RUNNER_LABELS: self-hosted
        TARGET_ARCH: x64
```

Then, build and run the docker container.

```bash
# Build and run
docker compose build
docker compose up -d
```

## Original Repository

[repo](https://github.com/Dao-AILab/flash-attention)

```bibtex
@inproceedings{dao2022flashattention,
  title={Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author={Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2022}
}
@inproceedings{dao2023flashattention2,
  title={Flash{A}ttention-2: Faster Attention with Better Parallelism and Work Partitioning},
  author={Dao, Tri},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024}
}
```
